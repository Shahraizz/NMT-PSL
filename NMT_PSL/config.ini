[PREPROCESSING]

tokenizer = 'bpe'
input_lanuage = "English"
targ_language = "PSL"
val_rand_state = 37
val_size = 3000
batch_size_train = 64
batch_size_test = 500
batch_size_dev = 1000

[TRANSFORMER]

num_layers = 6,
dff = 2048,
num_heads = 4,
bert_enc = False,
d_model = 300,
tok_size = 42,
dropout_rate = 0.1,
embedding = 'bpe',
train_emb = False

